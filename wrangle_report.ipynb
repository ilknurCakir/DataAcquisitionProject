{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "div.cell { /* Tunes the space between cells */\n",
       "margin-top:1em;\n",
       "margin-bottom:1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
       "font-size: 2.2em;\n",
       "line-height:1.4em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
       "margin-bottom: -0.4em;\n",
       "}\n",
       "\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Times New Roman';\n",
       "font-size:1.3em;\n",
       "line-height:1.4em;\n",
       "padding-left:3em;\n",
       "padding-right:3em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.cell { /* Tunes the space between cells */\n",
    "margin-top:1em;\n",
    "margin-bottom:1em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 2.2em;\n",
    "line-height:1.4em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
    "margin-bottom: -0.4em;\n",
    "}\n",
    "\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.3em;\n",
    "line-height:1.4em;\n",
    "padding-left:3em;\n",
    "padding-right:3em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assessment and Cleaning\n",
    "\n",
    "df DataFrame contains enhanced twitter archive of @WeRateDogs Twitter account. There are tweet_id, timestamp, text, rating_numerator, rating_denominator, name, doggo, floofer, puppo, pupper columns among others which I will not use for the analysis. \n",
    "\n",
    "First, I check df to see if there are duplicated rows. All tweet ids are unique and there is no duplicated instances.\n",
    "\n",
    "Last 4 columns do not comply with the definition of tidy data. All 4 columns can be gathered into a single column representing dog stage since these columns are mutually exclusive, ie. if the dog is puppo then it cannot be doggo, floofer or pupper at the same time. I call this column dog_stage. If there is no information about dog stage, then it is np.NaN instead of 'None'.\n",
    "\n",
    "There are some entries that are not dog names in the name column like a, an, the, very, actually etc. It seems that while extracting names from text of the tweet, code gets the word after 'This is'. Not all words coming after 'This is' are dog names. So it needs cleaning. These words all start with lower case whereas valid dog name entries all start with upper case. I printed all values in name column that do not capitalized and visually inspect them. It supports mystrategy, none of them is  a valid dog name. I changed all values that are not names (starts with lower case) to NaN.\n",
    "\n",
    "Name column also includes string 'None'. It is used to say there is no dog name in the tweet. So I change all \"None' objects to np.NaN s.\n",
    "\n",
    "The ratings are on a scale of 10, so we expect rating_denominator variable to be all 10. But when I inspect it, there are some values that do not make sense like 110, 120... It could be intentional or due to unclean data. It needs further assessment. There are 23 values different than 10 for rating_denominator variable. When I printed text of these samples, it seems that some are intentional but some are due to poor job in extracting them from text in the first place. I visually inspect them and change manually ones that need to be changed. If text does not include any rating, I simply assign np.NaN.\n",
    "\n",
    "After correcting erroneous denominator values, I drop null values. It basically says corresponding tweet does not include any rating and we do not want any tweet with no rating in this analysis.\n",
    "\n",
    "The next step is about denominator values that are greater than 10 inputted intentionally. We can convert these ratings to those with a scale of 10.  If the rating is 84/70, it is simply 12/10. If denominator is greater than 10, divide it by 10 and scale down corresponding numerator accordingly. At the end, all denominator values are 10.\n",
    "\n",
    "After scaling denominator values to 10, now the turn is for numerator values. There are values greater than 10, some of them are because of the unique rating system of WeRateDogs account. But even with keeping this in mind, some values seem so skeptical like 182, 420, 1776. As in denominator case, through inspection would be so beneficial for clean data. Printing text variable of these values, some are erroneous because dot is not captured while extracting the value from text in the first place. Instead of 11.27, it gets 1127. All these values are corrected manually. Other intentional high values are kept as they are.\n",
    "\n",
    "We only want original tweets with ratings. Some of the data are Retweets, all text values that start with 'RT' are dropped.\n",
    "\n",
    "\n",
    "Also, image predictions file does not include data for images that tweeted after August 1st, 2017. Checking to see if we have any tweets after this date would ensure us. I converted timestamp column to Datetime variable and checked it to see if there is any tweet that belongs to time later than August, 2017. It does not include any tweets after August, 2017.\n",
    "\n",
    "Now dataframe is clean enough to make analysis, it is time to add RT and Favorite counts to the table. I call this table 'merged', and after merging images table which include image predictions, I call 'final' to finalized table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
